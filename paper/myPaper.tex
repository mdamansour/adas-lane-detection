%% Technical Report - Vision-Based Lane Detection
% Author: Mohammed Amansour
% Institution: Faculty of Sciences and Technology, Fes

\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}

\geometry{top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm}

\title{\textbf{Real-Time Vision-Based Lane Detection for ADAS}\\
\large Technical Report \& Implementation Guide}

\author{Mohammed Amansour\\
Faculty of Sciences and Technology, Fes\\
Master in Electrical Engineering and Embedded Systems}

\date{February 2026}

\begin{document}

\maketitle

\begin{abstract}
This report details the mathematical foundations, system architecture, and usage of the ADAS Lane Detection system. Developed in MATLAB R2025b, the system implements a pipeline for real-time lane tracking using illimunation-invariant HSV segmentation, Canny edge detection, and temporal ROI tracking. The report serves as a complete reference for the algorithmic design and future embedded deployment.
\end{abstract}

\tableofcontents
\newpage

\section{Introduction}
Lane detection is a critical perception task for Advanced Driver Assistance Systems (ADAS). This project provides a modular algorithm capable of detecting lane boundaries under varying lighting conditions (shadows, tunnels) and predicting vehicle turn direction (Left/Right/Straight).

The system prioritizes deterministic Computer Vision techniques over "black box" Deep Learning approaches to ensure explainability and efficiency on embedded hardware.

\section{System Architecture}
The codebase is organized into three logical layers: Perception, Estimation, and Visualization.

\subsection{File Structure \& Roles}
\begin{itemize}
    \item \textbf{Core Logic:}
    \begin{itemize}
        \item \texttt{src/main\_process\_video.m}: The entry point. Loops through video frames and orchestrates the pipeline.
    \end{itemize}
    
    \item \textbf{Perception Layer:}
    \begin{itemize}
        \item \texttt{getAdaptiveThresholds.m}: Computes dynamic luminance stats and HSV color thresholds.
        \item \texttt{buildRoiEdges.m}: Performs Gaussian smoothing, HSV masking, Canny detection, and ROI cropping.
        \item \texttt{detectHoughLines.m}: Extracts linear features from the edge map using the Hough Transform.
    \end{itemize}
    
    \item \textbf{Estimation Layer:}
    \begin{itemize}
        \item \texttt{collectLanePoints.m}: Selects left/right candidates using geometry and tracking corridors.
        \item \texttt{updateLaneState.m}: Fits polynomials and applies Exponential Moving Average (EMA) smoothing.
        \item \texttt{computeVanishingPoint.m}: Calculates intersection of lane models for turn prediction.
    \end{itemize}
    
    \item \textbf{Visualization:}
    \begin{itemize}
        \item \texttt{drawOverlay.m}: Renders lane polygons and HUD text.
        \item \texttt{generateLaneCurves.m}: Generates smooth visualization points with horizon fading.
    \end{itemize}
\end{itemize}

\section{Mathematical Foundations}

\subsection{Preprocessing: Gaussian Smoothing}
To suppress high-frequency sensor noise, a 3D Gaussian filter is applied:
\begin{equation}
G(x, y; \sigma) = \frac{1}{2\pi\sigma^2} \exp\left(-\frac{x^2 + y^2}{2\sigma^2}\right)
\end{equation}
This allows subsequent edge detectors to focus on significant structural boundaries rather than thermal noise or compression artifacts.

\subsection{Perception: HSV Color Segmentation}
Fixed RGB thresholds fail in shadows where intensity drops across all channels. We utilize the HSV (Hue, Saturation, Value) color space to decouple chromatic information from brightness.

\textbf{Yellow Lane Detection:}
Defined by Hue angle, which remains stable ($\sim 30^{\circ}-60^{\circ}$) even in deep shadow:
\begin{equation}
M_{\text{yellow}} = (H \in [0.08, 0.17]) \land (S \geq 0.4) \land (V \geq V_{\text{adaptive}})
\end{equation}

\textbf{White Lane Detection:}
Defined by low saturation (achromatic) and high relative brightness:
\begin{equation}
M_{\text{white}} = (S \leq 0.25) \land (V \geq V_{\text{adaptive}})
\end{equation}

The adaptive Value threshold $V_{\text{adaptive}}$ scales linearly with global frame luminance $\mu_L$ to handle exposure changes.

\subsection{Region of Interest (ROI) \& Horizon Clamp}
The processing area is restricted to a trapezoid $\mathbf{V}_{\text{ROI}}$ capturing the road surface. Crucially, the top edge is clamped to the image midline ($y = 0.5H$) to prevent processing sky or distant terrain:
\begin{equation}
y_{\text{top}} = \max(0.5H, \text{Horizon}_{\text{estimated}})
\end{equation}
This "Horizon Clamp" eliminates false positives from tree lines or mountain ridges.

\subsection{Estimation: ROI Tracking with Temporal Priors}
To reject transient false positives (guardrails, adjacent cars), the system operates in two modes:

\begin{enumerate}
    \item \textbf{Acquisition Mode:} Global search for lane candidates (used in first frame or after track loss).
    \item \textbf{Tracking Mode:} Search is restricted to a narrow corridor around the previous frame's polynomial model:
\end{enumerate}

\begin{equation}
|x_i - \hat{x}_{t-1}(y_i)| < 50 \text{ pixels}
\end{equation}

Line segments are only accepted if $>60\%$ of their points fall within this corridor. This temporal regularization reduces susceptibility to outliers.

\section{Usage Guide}

\subsection{Prerequisites}
\begin{itemize}
    \item MATLAB R2024b/2025b
    \item Computer Vision Toolbox
    \item Automated Driving Toolbox
\end{itemize}

\subsection{Running the Algorithm}
1. Place input video in \texttt{data/test\_drive.mp4}.
2. Open MATLAB and navigate to the \texttt{src/} directory.
3. Execute the main script:
\begin{lstlisting}[language=Matlab]
>> main_process_video
\end{lstlisting}
4. The output will be visualized in real-time windows and saved to \texttt{data/output\_annotated.avi}.

\section{Future Work}
\begin{itemize}
    \item \textbf{Kalman Filter:} Replace the EMA smoother with a Kalman Filter to predict lane position during occlusions based on velocity/acceleration models.
    \item \textbf{Curvature Estimation:} Calculate the quantitative radius of curvature to assess road tightnes ($R = [1+(y')^2]^{3/2} / |y''|$).
    \item \textbf{Embedded C++ Port:} Use MATLAB Coder to generate C++ source for deployment on Raspberry Pi 5.
\end{itemize}

\end{document}
